{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f4b5523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset = List((1,2013-07-25,11599,CLOSED), (2,2014-07-25,256,PENDING), (3,2013-07-25,11599,COMPLETE), (4,2019-07-25,8827,CLOSED))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "List((1,2013-07-25,11599,CLOSED), (2,2014-07-25,256,PENDING), (3,2013-07-25,11599,COMPLETE), (4,2019-07-25,8827,CLOSED))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// loading the data into a datset \n",
    "val dataset=List((1,\"2013-07-25\",11599,\"CLOSED\"),(2,\"2014-07-25\",256,\"PENDING\"),(3,\"2013-07-25\",11599,\"COMPLETE\"),(4,\"2019-07-25\",8827,\"CLOSED\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b12e5305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdd = ParallelCollectionRDD[2] at parallelize at <console>:43\n",
       "df = [order_id: int, order_date: string ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[order_id: int, order_date: string ... 2 more fields]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// converting the dataset into a rdd then convert it to a dataframe\n",
    "val rdd=sc.parallelize(dataset)\n",
    "// converting the rdd to a dataframe \n",
    "val df =rdd.toDF(\"order_id\",\"order_date\",\"customer_id\",\"status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0e3f7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "st_df = [order_id: int, order_date: string ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[order_id: int, order_date: string ... 2 more fields]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// converting the list datastructure to a dataset using a Structured API and converting to a dataframe\n",
    "val st_df=spark.createDataFrame(dataset).toDF(\"order_id\",\"order_date\",\"customer_id\",\"status\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "985fb672",
   "metadata": {},
   "outputs": [
    {
     "ename": "Unknown Error",
     "evalue": "<console>:44: error: stable identifier required, but this.$line7$read.spark.implicits found.\n       import spark.implicits._\n                    ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "// checking the schema as we have to convert the string to date datatype\n",
    "st_df.printSchema()\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types.DateType\n",
    "import spark.implicits._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2a3bae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "st_df1 = [order_id: int, order_date: bigint ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[order_id: int, order_date: bigint ... 2 more fields]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// now let us convert the order_date to epoxy time using a timestamp function\n",
    "// for this we will use the .withColumn because it will replace the column or add new column\n",
    "\n",
    "val st_df1=st_df.withColumn(\"order_date\",unix_timestamp(col(\"order_date\").cast(DateType)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fdfab317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = false)\n",
      " |-- order_date: long (nullable = true)\n",
      " |-- customer_id: integer (nullable = false)\n",
      " |-- status: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"root\n",
       "-- order_id: integer (nullable = false)\n",
       "-- order_date: long (nullable = true)\n",
       "-- customer_id: integer (nullable = false)\n",
       "-- status: string (nullable = true)\n",
       "\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// checking whether the date columns has been converted or not.\n",
    "st_df1.printSchema()\n",
    "\"\"\"root\n",
    " |-- order_id: integer (nullable = false)\n",
    " |-- order_date: long (nullable = true)\n",
    " |-- customer_id: integer (nullable = false)\n",
    " |-- status: string (nullable = true)\n",
    "\"\"\"\n",
    "// as we can see that the datatype of order has been changed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4ec51fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df2 = [order_id: int, order_date: bigint ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[order_id: int, order_date: bigint ... 3 more fields]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// cretaing a new column with name \"newid\" and make sure it has unique ids and using a montonic increasing function\n",
    "var df2=st_df1.withColumn(\"newid\",monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76051673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+--------+-----+\n",
      "|order_id|order_date|customer_id|  status|newid|\n",
      "+--------+----------+-----------+--------+-----+\n",
      "|       1|1374724800|      11599|  CLOSED|    0|\n",
      "|       2|1406260800|        256| PENDING|    1|\n",
      "|       3|1374724800|      11599|COMPLETE|    2|\n",
      "|       4|1564027200|       8827|  CLOSED|    3|\n",
      "+--------+----------+-----------+--------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "+--------+----------+-----------+--------+-----+\n",
       "order_id|order_date|customer_id|  status|newid|\n",
       "+--------+----------+-----------+--------+-----+\n",
       "       1|1374724800|      11599|  CLOSED|    0|\n",
       "       2|1406260800|        256| PENDING|    1|\n",
       "       3|1374724800|      11599|COMPLETE|    2|\n",
       "       4|1564027200|       8827|  CLOSED|    3|\n",
       "+--------+----------+-----------+--------+-----+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "df2.show()\n",
    "\"\"\"+--------+----------+-----------+--------+-----+\n",
    "|order_id|order_date|customer_id|  status|newid|\n",
    "+--------+----------+-----------+--------+-----+\n",
    "|       1|1374724800|      11599|  CLOSED|    0|\n",
    "|       2|1406260800|        256| PENDING|    1|\n",
    "|       3|1374724800|      11599|COMPLETE|    2|\n",
    "|       4|1564027200|       8827|  CLOSED|    3|\n",
    "+--------+----------+-----------+--------+-----+\"\"\"\n",
    "// checking whether the new column has been added "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "65c5be73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+-------+-----+\n",
      "|order_id|order_date|customer_id| status|newid|\n",
      "+--------+----------+-----------+-------+-----+\n",
      "|       4|1564027200|       8827| CLOSED|    3|\n",
      "|       2|1406260800|        256|PENDING|    1|\n",
      "|       1|1374724800|      11599| CLOSED|    0|\n",
      "+--------+----------+-----------+-------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df3 = [order_id: int, order_date: bigint ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[order_id: int, order_date: bigint ... 3 more fields]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// dropping the column which have same order_date and customer_id column values\n",
    "val df3=df2.dropDuplicates(\"order_date\",\"customer_id\")\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "59d4efd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df4 = [order_date: bigint, customer_id: int ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[order_date: bigint, customer_id: int ... 2 more fields]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// drop the order_id column\n",
    "val df4=df3.drop(\"order_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0becbf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------+-----+\n",
      "|order_date|customer_id|  status|newid|\n",
      "+----------+-----------+--------+-----+\n",
      "|1406260800|        256| PENDING|    1|\n",
      "|1374724800|      11599|COMPLETE|    2|\n",
      "|1564027200|       8827|  CLOSED|    3|\n",
      "+----------+-----------+--------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df5 = [order_date: bigint, customer_id: int ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[order_date: bigint, customer_id: int ... 2 more fields]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// sort the data on the basis od new_id\n",
    "val df5=df4.sort(\"newid\")\n",
    "df5.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd8ea8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 2 - Scala",
   "language": "scala",
   "name": "spark_2_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

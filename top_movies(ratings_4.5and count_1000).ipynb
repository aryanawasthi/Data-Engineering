{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06340662",
   "metadata": {},
   "outputs": [],
   "source": [
    "//load the movies data from hdfs stored as movies\n",
    "val rdd1=sc.textFile(\"movies\")\n",
    "// loaded data has 4 coloumns but we require only movie_id and movie name threrfore we map these 2 values out\n",
    "val rdd2=rdd1.map(x=>{\n",
    "          val fields=x.split(\"::\")\n",
    "          (fields(0),fields(1))\n",
    "      })\n",
    "// loading the ratings file from hdfs\n",
    "\n",
    "val ratings=sc.textFile(\"ratings\")\n",
    "// rating file has many columns so but we have\n",
    "// input (user_id,movie_id,rating,timestamp)\n",
    "//output (movie_id,ratings)\n",
    "val new_ratings=ratings.map(x=>{\n",
    "          val fields=x.split(\"::\")\n",
    "          (fields(1),fields(2))\n",
    "      })\n",
    "// input (1127,4.5)\n",
    "// output (1127,(4.5,1.0))\n",
    "\n",
    "val rdd3=new_ratings.map(x=>{\n",
    "     |     (x._1,(x._2.toFloat,1.0))\n",
    "     |     \n",
    "     | });\n",
    "\n",
    "// input (1127,(4.5,1.0)),(1127,(5,1)),(1127,(3.5,1))\n",
    "// output (1127,(13,3))\n",
    "val aggregation=rdd3.reduceByKey((x,y)=>(x._1+y._1,x._2+y._2))\n",
    "// can be done in the above step as optimization \n",
    "val rdd4=rdd3.map(x=>(x._1,(x._2._1.toFloat,x._2._2.toFloat)));\n",
    "// input (1127,(13,3))\n",
    "// output (only those movies which have count greater than 1000 have to be filtered out)\n",
    "val rdd6=rdd5.filter(x=>x._2._2>1000)\n",
    "// find the average rating  by sum(ratings)/numberofratings\n",
    "val rdd7=rdd6.map(x=>(x._1,x._2._1/x._2._2))\n",
    "// filter only those movies where ratings are greater than 4.5\n",
    "val final_movies=rdd7.filter(x=>x._2>4.5)\n",
    "// input (movie_id,ratings) and  (movie_id,names)\n",
    "//output(movie_id,(name,ratings))\n",
    "\n",
    "\n",
    "val joineed=final_movies.join(rdd2)\n",
    "// input (movie_id,(movie_name,ratings))\n",
    "//output (movie_name)\n",
    "val top_movies=joineed.map(x=>x._2._2)\n",
    "\n",
    "val sorted_top_movies=joineed.sortBy(x=>x._2._1)\n",
    "sorted_top_movies.collect\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 2 - Scala",
   "language": "scala",
   "name": "spark_2_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
